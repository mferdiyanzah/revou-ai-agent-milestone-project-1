# ğŸ¦ TReA - Treasury with Embedded AI

**Multimodal Agentic AI for Treasury Document Processing & Journal Mapping**

TReA is a comprehensive Streamlit application that automates treasury document processing using advanced AI capabilities. It processes **multiple input formats** including PDF statements, text files, JSON data, and CSV files from banks (like DBS Singapore), extracts transaction data, and automatically maps them to appropriate journal entries.

## ğŸ¯ Features

- **ğŸ“„ Multimodal Document Upload**: Upload treasury data in multiple formats (PDF, TXT, JSON, CSV)
- **ğŸ¤– Automated Processing**: AI-powered extraction and transformation of financial data
- **ğŸ“Š Transaction Analysis**: Automatic categorization and mapping of transactions
- **ğŸ” Smart Definition Search**: Brave Search integration for transaction type definitions
- **ğŸ“ˆ Analytics Dashboard**: Historical processing data and trends visualization
- **âš™ï¸ System Monitoring**: Real-time health checks and configuration management
- **ğŸ”’ Secure**: Token-based authentication and file validation
- **ğŸ“± Responsive UI**: Modern, intuitive interface built with Streamlit

## ğŸ—ï¸ Architecture

```
TReA Application
â”œâ”€â”€ Frontend (Streamlit)
â”‚   â”œâ”€â”€ Multimodal Document Upload
â”‚   â”œâ”€â”€ Processing Dashboard
â”‚   â””â”€â”€ Analytics & Monitoring
â”œâ”€â”€ Backend Services
â”‚   â”œâ”€â”€ PDF Processing Pipeline (TReA API)
â”‚   â”œâ”€â”€ Text/JSON/CSV Processing (Direct)
â”‚   â”œâ”€â”€ AI/ML Models
â”‚   â””â”€â”€ Database Integration
â””â”€â”€ TReA API Backend
    â”œâ”€â”€ PDF Parser Service
    â”œâ”€â”€ Data Transformation
    â””â”€â”€ Journal Mapping
```

## ğŸ“ Supported File Formats

### **ğŸ“„ PDF Files**
- **Format**: Treasury statements (DBS Singapore format)
- **Processing**: Full TReA backend API integration
- **Features**: Complete PDF parsing, text extraction, and database integration

### **ğŸ“ Text Files (.txt)**
- **Format**: Plain text transaction data
- **Pattern**: `TRANSACTION_TYPE ASSET_CLASS AMOUNT CURRENCY DATE DESCRIPTION`
- **Example**: `BUY STOCK 1000 USD 2024-01-15 Purchase of equity`
- **Processing**: Direct regex-based parsing

### **ğŸ“Š JSON Files (.json)**
- **Format**: Structured transaction data
- **Schema**: `{"transactions": [{"transaction_type": "BUY", "asset_class": "STOCK", ...}]}`
- **Processing**: Schema validation and object parsing
- **Features**: Flexible structure support

### **ğŸ“ˆ CSV Files (.csv)**
- **Format**: Tabular transaction data
- **Columns**: transaction_type, asset_class, amount, currency, date, description
- **Processing**: Automatic column mapping and pandas integration
- **Features**: Header detection and encoding support

## ğŸš€ Quick Start

### Prerequisites

- Python 3.12+
- uv package manager (recommended) or pip
- Access to TReA backend API (for PDF processing)
- Valid API token
- Optional: OpenAI API key, Brave Search API key

### Installation

1. **Clone the repository**
   ```bash
   git clone <repository-url>
   cd milestone-project-1-ai-agent
   ```

2. **Install dependencies**
   ```bash
   # Using uv (recommended)
   uv sync
   
   # Or using pip
   pip install -e .
   ```

3. **Configure environment**
   ```bash
   # Copy the environment template
   cp env.template .env
   
   # Edit .env with your configuration
   nano .env
   ```

4. **Run the application**
   ```bash
   # Using the main entry point (recommended)
   python main.py
   
   # Or using streamlit directly
   streamlit run main.py
   
   # Alternative: using uv
   uv run python main.py
   ```

5. **Access the application**
   - If using `python main.py`, the application will automatically launch in your browser
   - If using `streamlit run main.py`, navigate to `http://localhost:8501`

## âš™ï¸ Configuration

### Environment Variables

Create a `.env` file in the project root with the following variables:

```bash
# API Configuration (Required for PDF processing)
API_BASE_URL=http://192.168.74.211:30477
API_TOKEN=your_bearer_token_here

# AI/ML Configuration (Optional - enhances all formats)
OPENAI_API_KEY=your_openai_api_key_here
LLM_MODEL=gpt-4
EMBEDDING_MODEL=text-embedding-3-small

# Brave Search Configuration (Optional - adds definition lookup)
BRAVE_API_KEY=your_brave_api_key_here
BRAVE_SEARCH_ENABLED=true

# Database Configuration (Optional - enables vector similarity)
POSTGRES_HOST=localhost
POSTGRES_DB=trea_vector_db
POSTGRES_USER=your_user
POSTGRES_PASSWORD=your_password

# File Upload Settings
MAX_FILE_SIZE_MB=50
UPLOAD_DIR=uploads

# Application Settings
DEBUG=false
```

### API Token Setup

1. Obtain a valid Bearer token from your TReA backend administrator (for PDF processing)
2. Add the token to your `.env` file as `API_TOKEN`
3. The token will be automatically used for PDF processing requests

## ğŸ“‹ Usage Guide

### 1. **Document Processing**

#### **PDF Files** 
1. **Upload PDF**: Select a treasury statement PDF file
2. **Automatic Processing**: Full TReA backend integration
3. **Complete Pipeline**: Extract â†’ Transform â†’ Map â†’ Store
4. **Database Integration**: Direct journal entry creation

#### **Text/JSON/CSV Files**
1. **Upload File**: Select your text, JSON, or CSV file
2. **Direct Processing**: No external API dependency
3. **AI Enhancement**: Definition lookup and analysis
4. **Quick Results**: Immediate processing and insights

### 2. **Processing Pipeline**

#### **PDF Processing Flow**
1. **File Upload** â†’ Save to temporary location
2. **API Upload** â†’ Send to TReA backend
3. **Content Extraction** â†’ Extract text and structure from PDF
4. **Data Transformation** â†’ Convert to structured transaction data
5. **Journal Mapping** â†’ Map transactions to appropriate journal entries

#### **Text-based Processing Flow**
1. **File Upload** â†’ Save and validate format
2. **Content Parsing** â†’ Extract using format-specific parser
3. **Data Structuring** â†’ Convert to standard transaction format
4. **AI Enhancement** â†’ Add definitions and analysis
5. **Mock Mapping** â†’ Create rule-based journal entries

### 3. **Analytics Dashboard**

- View processing success rates across all formats
- Analyze transaction type distributions
- Track historical processing data
- Export transaction data as CSV
- Source format indicators and metrics

### 4. **System Monitoring**

- Real-time API health checks
- Service availability for all processors
- Configuration validation
- Multimodal error troubleshooting guides

## ğŸ“Š Transaction Types & Journal Classification

The system supports these transaction types across all input formats and automatically classifies them into appropriate journal types:

### **ğŸ’° Invoice Transactions â†’ PAYMENT Journal**
- **Trading**: Buy, Purchase, Subscription
- **Investment**: Placement, Investment, Acquisition
- **Cash Management**: Deposit, Transfer_Out, Payment

### **ğŸ’¸ Debit Memo Transactions â†’ REFUND Journal**
- **Trading**: Sell, Disposal, Redemption
- **Income**: Dividend, Interest, Coupon, Revenue
- **Cash Management**: Withdrawal, Transfer_In, Receipt
- **Maturity**: Maturity, Repayment, Early Termination

### **ğŸ¯ Journal Mapping Logic**
Each transaction is automatically classified as either:
- **Invoice** â†’ Creates **Payment** journal entries (money going out)
- **Debit Memo** â†’ Creates **Refund** journal entries (money coming in)

## ğŸ› ï¸ Development

### Project Structure

```
milestone-project-1-ai-agent/
â”œâ”€â”€ src/                    # Main source code
â”‚   â”œâ”€â”€ config.py          # Configuration settings
â”‚   â”œâ”€â”€ services/          # API and external services
â”‚   â”œâ”€â”€ processors/        # Document processing logic
â”‚   â”‚   â”œâ”€â”€ pdf_processor.py      # PDF processing
â”‚   â”‚   â”œâ”€â”€ text_processor.py     # Text/JSON/CSV processing
â”‚   â”‚   â””â”€â”€ ai_processor.py       # Multimodal AI enhancement
â”‚   â””â”€â”€ ui/               # Streamlit UI components
â”œâ”€â”€ examples/              # Sample input files
â”‚   â”œâ”€â”€ sample_transaction_data.json
â”‚   â”œâ”€â”€ sample_transaction_data.csv
â”‚   â””â”€â”€ sample_transaction_data.txt
â”œâ”€â”€ main.py               # Main application entry point
â”œâ”€â”€ app.py                # Alternative Streamlit entry point
â”œâ”€â”€ pyproject.toml        # Project dependencies
â”œâ”€â”€ .streamlit/           # Streamlit configuration
â”œâ”€â”€ uploads/              # Temporary file storage
â”œâ”€â”€ data/                 # Application data
â””â”€â”€ docs/                 # Documentation
```

### Adding New File Formats

1. **Extend TextProcessor**: Add new format parsing in `src/processors/text_processor.py`
2. **Update Configuration**: Add file extension to `src/config.py`
3. **Enhance UI**: Update file upload component in `src/ui/components.py`
4. **Add Validation**: Extend file validator for new format

### Running in Development

```bash
# Enable debug mode
export DEBUG=true

# Run with auto-reload (option 1)
python main.py

# Run with auto-reload (option 2)
streamlit run main.py --server.runOnSave true
```

## ğŸ”§ Troubleshooting

### Common Issues

1. **API Connection Failed** (PDF processing)
   - Verify API_BASE_URL is correct
   - Check if API token is valid and not expired
   - Ensure network connectivity to the backend

2. **File Upload Issues**
   - Check file size (must be < 50MB)
   - Ensure file format is supported (PDF, TXT, JSON, CSV)
   - Verify file encoding for text-based formats

3. **Processing Errors**
   - **PDF**: Check API backend logs and TReA service status
   - **Text/JSON/CSV**: Verify file format and structure
   - **JSON**: Validate JSON syntax and schema
   - **CSV**: Check column headers and encoding

4. **Format-Specific Issues**
   - **JSON**: Ensure `transactions` array exists in root object
   - **CSV**: Verify column headers match expected format
   - **Text**: Check line format matches pattern

### Debug Mode

Enable debug mode by setting `DEBUG=true` in your `.env` file for detailed error messages and stack traces.

## ğŸ“ˆ Sample Data

The `examples/` directory contains sample files for each supported format:

- `sample_transaction_data.json` - JSON format example
- `sample_transaction_data.csv` - CSV format example  
- `sample_transaction_data.txt` - Text format example

Use these files to test the multimodal capabilities of the system.

## ğŸ¤ Contributing

1. Fork the repository
2. Create a feature branch (`git checkout -b feature/amazing-feature`)
3. Commit your changes (`git commit -m 'Add amazing feature'`)
4. Push to the branch (`git push origin feature/amazing-feature`)
5. Open a Pull Request

## ğŸ“„ License

This project is part of the Milestone Project for the AI Agent course.

## ğŸ†˜ Support

For support and questions:

1. Check the troubleshooting section above
2. Review the system status page in the application
3. Test with sample files in the `examples/` directory
4. Contact the development team
5. Create an issue in the repository

---

**ğŸ‰ Now supports multimodal input processing! Built with â¤ï¸ for automated treasury operations**


